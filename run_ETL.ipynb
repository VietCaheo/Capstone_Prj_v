{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start process the SAS labels Description file ... \n",
      "\n",
      "Debug read sas Labels files................ \n",
      "\n",
      "Type of lines is  <class 'list'>\n",
      "To check PortCityState_df :\n",
      "  PortCode                  CityName StateCode\n",
      "0      ANC                 ANCHORAGE        AK\n",
      "1      BAR  BAKER AAF - BAKER ISLAND        AK\n",
      "2      DAC             DALTONS CACHE        AK\n",
      "3      PIZ    DEW STATION PT LAY DEW        AK\n",
      "4      DTH              DUTCH HARBOR        AK\n",
      "PortCode     590\n",
      "CityName     590\n",
      "StateCode    590\n",
      "dtype: int64\n",
      "\n",
      " ----------------------------------------------------\n",
      "Start process the Immigration Data sas7dat ... \n",
      "\n",
      "\n",
      " Accumulating Read into sas_data Schema for 1 sas data files .... \n",
      "\n",
      "3096313\n",
      "\n",
      " Schema of staging Immigra_data ------------------------------------- \n",
      "\n",
      "root\n",
      " |-- cicid: double (nullable = true)\n",
      " |-- i94yr: double (nullable = true)\n",
      " |-- i94mon: double (nullable = true)\n",
      " |-- i94cit: double (nullable = true)\n",
      " |-- i94res: double (nullable = true)\n",
      " |-- i94port: string (nullable = true)\n",
      " |-- arrdate: double (nullable = true)\n",
      " |-- i94mode: double (nullable = true)\n",
      " |-- i94addr: string (nullable = true)\n",
      " |-- depdate: double (nullable = true)\n",
      " |-- i94bir: double (nullable = true)\n",
      " |-- i94visa: double (nullable = true)\n",
      " |-- count: double (nullable = true)\n",
      " |-- dtadfile: string (nullable = true)\n",
      " |-- visapost: string (nullable = true)\n",
      " |-- occup: string (nullable = true)\n",
      " |-- entdepa: string (nullable = true)\n",
      " |-- entdepd: string (nullable = true)\n",
      " |-- entdepu: string (nullable = true)\n",
      " |-- matflag: string (nullable = true)\n",
      " |-- biryear: double (nullable = true)\n",
      " |-- dtaddto: string (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      " |-- insnum: string (nullable = true)\n",
      " |-- airline: string (nullable = true)\n",
      " |-- admnum: double (nullable = true)\n",
      " |-- fltno: string (nullable = true)\n",
      " |-- visatype: string (nullable = true)\n",
      "\n",
      "+-----+------+------+------+------+-------+-------+-------+-------+-------+------+-------+-----+--------+--------+-----+-------+-------+-------+-------+-------+--------+------+------+-------+--------------+-----+--------+\n",
      "|cicid| i94yr|i94mon|i94cit|i94res|i94port|arrdate|i94mode|i94addr|depdate|i94bir|i94visa|count|dtadfile|visapost|occup|entdepa|entdepd|entdepu|matflag|biryear| dtaddto|gender|insnum|airline|        admnum|fltno|visatype|\n",
      "+-----+------+------+------+------+-------+-------+-------+-------+-------+------+-------+-----+--------+--------+-----+-------+-------+-------+-------+-------+--------+------+------+-------+--------------+-----+--------+\n",
      "|  6.0|2016.0|   4.0| 692.0| 692.0|    XXX|20573.0|   null|   null|   null|  37.0|    2.0|  1.0|    null|    null| null|      T|   null|      U|   null| 1979.0|10282016|  null|  null|   null| 1.897628485E9| null|      B2|\n",
      "|  7.0|2016.0|   4.0| 254.0| 276.0|    ATL|20551.0|    1.0|     AL|   null|  25.0|    3.0|  1.0|20130811|     SEO| null|      G|   null|      Y|   null| 1991.0|     D/S|     M|  null|   null|  3.73679633E9|00296|      F1|\n",
      "| 15.0|2016.0|   4.0| 101.0| 101.0|    WAS|20545.0|    1.0|     MI|20691.0|  55.0|    2.0|  1.0|20160401|    null| null|      T|      O|   null|      M| 1961.0|09302016|     M|  null|     OS|  6.66643185E8|   93|      B2|\n",
      "| 16.0|2016.0|   4.0| 101.0| 101.0|    NYC|20545.0|    1.0|     MA|20567.0|  28.0|    2.0|  1.0|20160401|    null| null|      O|      O|   null|      M| 1988.0|09302016|  null|  null|     AA|9.246846133E10|00199|      B2|\n",
      "| 17.0|2016.0|   4.0| 101.0| 101.0|    NYC|20545.0|    1.0|     MA|20567.0|   4.0|    2.0|  1.0|20160401|    null| null|      O|      O|   null|      M| 2012.0|09302016|  null|  null|     AA|9.246846313E10|00199|      B2|\n",
      "+-----+------+------+------+------+-------+-------+-------+-------+-------+------+-------+-----+--------+--------+-----+-------+-------+-------+-------+-------+--------+------+------+-------+--------------+-----+--------+\n",
      "only showing top 5 rows\n",
      "\n",
      "\n",
      " Loading data to table .... \n",
      "\n",
      "Show schema of D_DateTime_table ...\n",
      "\n",
      "root\n",
      " |-- ArriveDate: string (nullable = true)\n",
      " |-- ArriveYear: integer (nullable = true)\n",
      " |-- ArriveMonth: integer (nullable = true)\n",
      " |-- ArriveDay: integer (nullable = true)\n",
      " |-- Arrive_DayOfWeek: string (nullable = true)\n",
      " |-- DepartureDate: string (nullable = true)\n",
      "\n",
      "+----------+----------+-----------+---------+----------------+-------------+\n",
      "|ArriveDate|ArriveYear|ArriveMonth|ArriveDay|Arrive_DayOfWeek|DepartureDate|\n",
      "+----------+----------+-----------+---------+----------------+-------------+\n",
      "|2016-04-29|      2016|          4|       29|          Friday|         null|\n",
      "|2016-04-07|      2016|          4|        7|        Thursday|         null|\n",
      "|2016-04-01|      2016|          4|        1|          Friday|   2016-08-25|\n",
      "+----------+----------+-----------+---------+----------------+-------------+\n",
      "only showing top 3 rows\n",
      "\n",
      "\n",
      " Write parquet of D_DateTime_table table  ... ... \n",
      "\n",
      "Do Quality check: data existing and data consistency... \n",
      "\n",
      "Data is Existing in target tables and is Consistent before and after Write parquet. OK NOW, MOVE NEXT! \n",
      "\n",
      " Process basic cleaning data before load to Fact_Immigrant table  ...\n",
      "\n",
      " show NaN values in dfS of Immigra_data...\n",
      "+-----+-----+------+------+------+-------+-------+-------+-------+-------+------+-------+-----+--------+--------+-------+-------+-------+-------+-------+-------+-------+------+-------+-------+------+-----+--------+\n",
      "|cicid|i94yr|i94mon|i94cit|i94res|i94port|arrdate|i94mode|i94addr|depdate|i94bir|i94visa|count|dtadfile|visapost|  occup|entdepa|entdepd|entdepu|matflag|biryear|dtaddto|gender| insnum|airline|admnum|fltno|visatype|\n",
      "+-----+-----+------+------+------+-------+-------+-------+-------+-------+------+-------+-----+--------+--------+-------+-------+-------+-------+-------+-------+-------+------+-------+-------+------+-----+--------+\n",
      "|    0|    0|     0|     0|     0|      0|      0|    239| 152592| 142457|   802|      0|    0|       1| 1881250|3088187|    238| 138429|3095921| 138429|    802|    477|414269|2982605|  83627|     0|19549|       0|\n",
      "+-----+-----+------+------+------+-------+-------+-------+-------+-------+------+-------+-----+--------+--------+-------+-------+-------+-------+-------+-------+-------+------+-------+-------+------+-----+--------+\n",
      "\n",
      "\n",
      " Droping NaN values here prior to  load to tables ... \n",
      "\n",
      "\n",
      " To show how many rows is being dropped when filtered by i94cit and ... 0\n",
      "Droping NaN  ....... \n",
      "\n",
      "to check any duplicated in dfS_ImmigAll ... \n",
      "\n",
      "\n",
      " Number of Immigra before drop_duplicates 3096313 \n",
      "\n",
      "\n",
      " Drop duplicated by cicid for make sure cicid is unique for each Immigrant Info...\n",
      "\n",
      " Number of Immigra after drop_duplicates 3096313 \n",
      "\n",
      "\n",
      " Loading data to table .... \n",
      "\n",
      "Show schema of Fact_Immigrant table ...\n",
      "\n",
      "root\n",
      " |-- Immig_Fact_ID: long (nullable = false)\n",
      " |-- cicid_Immigrant: double (nullable = true)\n",
      " |-- AirPortCode: string (nullable = true)\n",
      " |-- ArriveDate: string (nullable = true)\n",
      " |-- DepartureDate: string (nullable = true)\n",
      " |-- FromResidence: double (nullable = true)\n",
      " |-- VisaType: string (nullable = true)\n",
      " |-- AdminNumber: double (nullable = true)\n",
      "\n",
      "+-------------+---------------+-----------+----------+-------------+-------------+--------+---------------+\n",
      "|Immig_Fact_ID|cicid_Immigrant|AirPortCode|ArriveDate|DepartureDate|FromResidence|VisaType|    AdminNumber|\n",
      "+-------------+---------------+-----------+----------+-------------+-------------+--------+---------------+\n",
      "|            0|          299.0|        NYC|2016-04-01|   2016-04-06|        103.0|      WT|5.5425872433E10|\n",
      "|            1|          305.0|        NYC|2016-04-01|   2016-04-11|        103.0|      WT|5.5425817433E10|\n",
      "|            2|          496.0|        CHI|2016-04-01|   2016-04-04|        103.0|      WB|5.5428623333E10|\n",
      "|            3|          558.0|        SFR|2016-04-01|   2016-04-03|        103.0|      WB|5.5433311133E10|\n",
      "|            4|          596.0|        NAS|2016-04-01|   2016-04-03|        103.0|      WT|5.5406105433E10|\n",
      "+-------------+---------------+-----------+----------+-------------+-------------+--------+---------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "Writing parquet files for Fact_Immigrant_table ... \n",
      "\n",
      "Do Quality check: data existing and data consistency... \n",
      "\n",
      "Data is Existing in target tables and is Consistent before and after Write parquet. OK NOW, MOVE NEXT! \n",
      "\n",
      " Droping NaN values for Dim Immigration detail info ... \n",
      "\n",
      "\n",
      " How many rows were dropped with subset ['fltno'] ... 19549\n",
      "Droping NaN  ....... \n",
      "\n",
      "\n",
      " Loading data to table .... \n",
      "\n",
      "Show schema of D_Immigrant_detail_table ...\n",
      "\n",
      "root\n",
      " |-- cicid_Immigrant: double (nullable = true)\n",
      " |-- Citizenship: double (nullable = true)\n",
      " |-- ArriveStateCode: string (nullable = true)\n",
      " |-- DepartureDate: double (nullable = true)\n",
      " |-- ArriveMode: double (nullable = true)\n",
      " |-- BirthYear: double (nullable = true)\n",
      " |-- Gender: string (nullable = true)\n",
      " |-- FlightNumber: string (nullable = true)\n",
      " |-- MatchArriveDeparture: string (nullable = true)\n",
      "\n",
      "+---------------+-----------+---------------+-------------+----------+---------+------+------------+--------------------+\n",
      "|cicid_Immigrant|Citizenship|ArriveStateCode|DepartureDate|ArriveMode|BirthYear|Gender|FlightNumber|MatchArriveDeparture|\n",
      "+---------------+-----------+---------------+-------------+----------+---------+------+------------+--------------------+\n",
      "|          299.0|      103.0|             NY|      20550.0|       1.0|   1962.0|  null|       00087|                   M|\n",
      "|          305.0|      103.0|             NY|      20555.0|       1.0|   1953.0|  null|       00087|                   M|\n",
      "|          496.0|      103.0|             IL|      20548.0|       1.0|   1952.0|  null|       00065|                   M|\n",
      "+---------------+-----------+---------------+-------------+----------+---------+------+------------+--------------------+\n",
      "only showing top 3 rows\n",
      "\n",
      "Do Quality check: data existing and data consistency... \n",
      "\n",
      "Data is Existing in target tables and is Consistent before and after Write parquet. OK NOW, MOVE NEXT! \n",
      "Finished process Immigration Data \n",
      "\n",
      "\n",
      " ----------------------------------------------------\n",
      "Start process the UsCities Demographic data ... \n",
      "\n",
      "Schema of staging UsCities ..... \n",
      "\n",
      "root\n",
      " |-- City: string (nullable = true)\n",
      " |-- State: string (nullable = true)\n",
      " |-- Median Age: double (nullable = true)\n",
      " |-- Male Population: integer (nullable = true)\n",
      " |-- Female Population: integer (nullable = true)\n",
      " |-- Total Population: integer (nullable = true)\n",
      " |-- Number of Veterans: integer (nullable = true)\n",
      " |-- Foreign-born: integer (nullable = true)\n",
      " |-- Average Household Size: double (nullable = true)\n",
      " |-- State Code: string (nullable = true)\n",
      " |-- Race: string (nullable = true)\n",
      " |-- Count: integer (nullable = true)\n",
      "\n",
      "+-------------+-------------+----------+---------------+-----------------+----------------+------------------+------------+----------------------+----------+------------------+-----+\n",
      "|         City|        State|Median Age|Male Population|Female Population|Total Population|Number of Veterans|Foreign-born|Average Household Size|State Code|              Race|Count|\n",
      "+-------------+-------------+----------+---------------+-----------------+----------------+------------------+------------+----------------------+----------+------------------+-----+\n",
      "|Silver Spring|     Maryland|      33.8|          40601|            41862|           82463|              1562|       30908|                   2.6|        MD|Hispanic or Latino|25924|\n",
      "|       Quincy|Massachusetts|      41.0|          44129|            49500|           93629|              4147|       32935|                  2.39|        MA|             White|58723|\n",
      "|       Hoover|      Alabama|      38.5|          38040|            46799|           84839|              4819|        8229|                  2.58|        AL|             Asian| 4759|\n",
      "+-------------+-------------+----------+---------------+-----------------+----------------+------------------+------------+----------------------+----------+------------------+-----+\n",
      "only showing top 3 rows\n",
      "\n",
      "\n",
      " Show NaN values in dfS of UsCities_data...\n",
      "+----+-----+----------+---------------+-----------------+----------------+------------------+------------+----------------------+----------+----+-----+\n",
      "|City|State|Median Age|Male Population|Female Population|Total Population|Number of Veterans|Foreign-born|Average Household Size|State Code|Race|Count|\n",
      "+----+-----+----------+---------------+-----------------+----------------+------------------+------------+----------------------+----------+----+-----+\n",
      "|   0|    0|         0|              3|                3|               0|                13|          13|                    16|         0|   0|    0|\n",
      "+----+-----+----------+---------------+-----------------+----------------+------------------+------------+----------------------+----------+----+-----+\n",
      "\n",
      "----------------------------------------------------------------------------\n",
      "\n",
      " Rows number in UsCities before drop_duplicates with subset['City'] 2891 \n",
      "\n",
      "Drop duplicated with subset ['City'] ...  \n",
      "\n",
      "\n",
      " Rows numbers in UsCities after drop_duplicates with subset['City'] 567 \n",
      "\n",
      "\n",
      " Loading data to table .... \n",
      "\n",
      "Show schema of Us_citites table after Joining ...\n",
      "\n",
      "root\n",
      " |-- AirPortCode: string (nullable = true)\n",
      " |-- CityName: string (nullable = true)\n",
      " |-- StateCode: string (nullable = true)\n",
      " |-- StateName: string (nullable = true)\n",
      " |-- MedianAge: double (nullable = true)\n",
      " |-- TotalPopulation: integer (nullable = true)\n",
      " |-- Veterans: integer (nullable = true)\n",
      " |-- ForeignBorn: integer (nullable = true)\n",
      " |-- AvgHouseholdSize: double (nullable = true)\n",
      " |-- Race: string (nullable = true)\n",
      "\n",
      "+-----------+--------+---------+-----------+---------+---------------+--------+-----------+----------------+--------------------+\n",
      "|AirPortCode|CityName|StateCode|  StateName|MedianAge|TotalPopulation|Veterans|ForeignBorn|AvgHouseholdSize|                Race|\n",
      "+-----------+--------+---------+-----------+---------+---------------+--------+-----------+----------------+--------------------+\n",
      "|       null|   CHINO|       CA| California|     36.5|          85599|    4186|      18666|            3.62|American Indian a...|\n",
      "|       null|STAMFORD|       CT|Connecticut|     35.4|         128877|    2269|      44003|             2.7|               Asian|\n",
      "|       null|  YAKIMA|       WA| Washington|     34.0|          93700|    4705|      15717|            2.74|  Hispanic or Latino|\n",
      "|       null|AMARILLO|       TX|      Texas|     33.8|         199651|   11008|      21124|            2.64|               White|\n",
      "|       null|  MUNCIE|       IN|    Indiana|     27.4|          69701|    2968|       1062|            2.35|American Indian a...|\n",
      "+-----------+--------+---------+-----------+---------+---------------+--------+-----------+----------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "\n",
      " how many rows in new table ... 578\n",
      "\n",
      " verfiry any How many NULL in AirPortCode column 445\n",
      "Start Writing parquet files for D_USCities_table ... \n",
      "\n",
      "Do Quality check: data existing and data consistency... \n",
      "\n",
      "Data is Existing in target tables and is Consistent before and after Write parquet. OK NOW, MOVE NEXT! \n",
      "Finished for us-cities data file.\n",
      "\n",
      " ----------------------------------------------------\n",
      "Start process the Airport data ... \n",
      "\n",
      "\n",
      " Schema of staging Airport ----------------\n",
      "\n",
      "root\n",
      " |-- ident: string (nullable = true)\n",
      " |-- type: string (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      " |-- elevation_ft: integer (nullable = true)\n",
      " |-- continent: string (nullable = true)\n",
      " |-- iso_country: string (nullable = true)\n",
      " |-- iso_region: string (nullable = true)\n",
      " |-- municipality: string (nullable = true)\n",
      " |-- gps_code: string (nullable = true)\n",
      " |-- iata_code: string (nullable = true)\n",
      " |-- local_code: string (nullable = true)\n",
      " |-- coordinates: string (nullable = true)\n",
      "\n",
      "+-----+-------------+--------------------+------------+---------+-----------+----------+------------+--------+---------+----------+--------------------+\n",
      "|ident|         type|                name|elevation_ft|continent|iso_country|iso_region|municipality|gps_code|iata_code|local_code|         coordinates|\n",
      "+-----+-------------+--------------------+------------+---------+-----------+----------+------------+--------+---------+----------+--------------------+\n",
      "|  00A|     heliport|   Total Rf Heliport|          11|       NA|         US|     US-PA|    Bensalem|     00A|     null|       00A|-74.9336013793945...|\n",
      "| 00AA|small_airport|Aero B Ranch Airport|        3435|       NA|         US|     US-KS|       Leoti|    00AA|     null|      00AA|-101.473911, 38.7...|\n",
      "| 00AK|small_airport|        Lowell Field|         450|       NA|         US|     US-AK|Anchor Point|    00AK|     null|      00AK|-151.695999146, 5...|\n",
      "+-----+-------------+--------------------+------------+---------+-----------+----------+------------+--------+---------+----------+--------------------+\n",
      "only showing top 3 rows\n",
      "\n",
      "\n",
      " to show NaN values in dfS of AirPort_data...\n",
      "+-----+----+----+------------+---------+-----------+----------+------------+--------+---------+----------+-----------+\n",
      "|ident|type|name|elevation_ft|continent|iso_country|iso_region|municipality|gps_code|iata_code|local_code|coordinates|\n",
      "+-----+----+----+------------+---------+-----------+----------+------------+--------+---------+----------+-----------+\n",
      "|    0|   0|   0|        7006|        0|          0|         0|        5676|   14045|    45886|     26389|          0|\n",
      "+-----+----+----+------------+---------+-----------+----------+------------+--------+---------+----------+-----------+\n",
      "\n",
      "\n",
      " Rows number of AirPort dfS before drop_duplicates with subset ['ident', 'name'] is : 55075 \n",
      "\n",
      "Drop duplicate with subset ['ident', 'name'] \n",
      "\n",
      " \n",
      " AirPort dfS after drop_duplicates with subset['ident', 'name'] 55075 \n",
      "\n",
      "\n",
      " Loading data to table .... \n",
      "\n",
      "Show schema of new D_Airport_table ...\n",
      "\n",
      "root\n",
      " |-- AirPortCode: string (nullable = true)\n",
      " |-- AirPortID: string (nullable = true)\n",
      " |-- Type: string (nullable = true)\n",
      " |-- AirportName: string (nullable = true)\n",
      " |-- CityName: string (nullable = true)\n",
      " |-- Elevation: integer (nullable = true)\n",
      " |-- Country: string (nullable = true)\n",
      " |-- Coordinates: string (nullable = true)\n",
      "\n",
      "+-----------+---------+--------------+--------------------+-------------------+---------+-------+--------------------+\n",
      "|AirPortCode|AirPortID|          Type|         AirportName|           CityName|Elevation|Country|         Coordinates|\n",
      "+-----------+---------+--------------+--------------------+-------------------+---------+-------+--------------------+\n",
      "|       null|     OISA| small_airport|      Abadeh Airport|             ABADEH|     5320|     IR|52.66666793823242...|\n",
      "|       null|     CYXX|medium_airport|  Abbotsford Airport|         ABBOTSFORD|      195|     CA|-122.361000061035...|\n",
      "|       null|  CA-CAB5|      heliport|Abbotsford (Regio...|         ABBOTSFORD|      287|     CA|-122.314048558, 4...|\n",
      "|       null|     ND07| small_airport|Punton Private Ai...|           ABSARAKA|     1105|     US|-97.4072036743164...|\n",
      "|       null|  MX-0693|      heliport|Centro de Gob. de...|ACAPULCO DE JUÃ¡REZ|      108|     MX|-99.897661, 16.85...|\n",
      "+-----------+---------+--------------+--------------------+-------------------+---------+-------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "\n",
      " how many rows in new table ... 55398\n",
      "\n",
      " verfiry any How many NULL in AirPortCode column 51792\n",
      "\n",
      " Writing and Reading Parquet files for dfS Airport ... ... \n",
      "\n",
      "Do Quality check: data existing and data consistency... \n",
      "\n",
      "Data is Existing in target tables and is Consistent before and after Write parquet. OK NOW, MOVE NEXT! \n",
      "\n",
      " ----------------------------------------------------\n",
      "Start process the World Temperature data ... \n",
      "\n",
      "to see how many rows in  dfS.count: 8599212\n",
      "\n",
      " Schema of staging Temp dfS-------------------------- \n",
      "\n",
      "root\n",
      " |-- dt: timestamp (nullable = true)\n",
      " |-- AverageTemperature: double (nullable = true)\n",
      " |-- AverageTemperatureUncertainty: double (nullable = true)\n",
      " |-- City: string (nullable = true)\n",
      " |-- Country: string (nullable = true)\n",
      " |-- Latitude: string (nullable = true)\n",
      " |-- Longitude: string (nullable = true)\n",
      "\n",
      "+-------------------+------------------+-----------------------------+-----+-------+--------+---------+\n",
      "|                 dt|AverageTemperature|AverageTemperatureUncertainty| City|Country|Latitude|Longitude|\n",
      "+-------------------+------------------+-----------------------------+-----+-------+--------+---------+\n",
      "|1743-11-01 00:00:00|             6.068|           1.7369999999999999|Århus|Denmark|  57.05N|   10.33E|\n",
      "|1743-12-01 00:00:00|              null|                         null|Århus|Denmark|  57.05N|   10.33E|\n",
      "+-------------------+------------------+-----------------------------+-----+-------+--------+---------+\n",
      "only showing top 2 rows\n",
      "\n",
      "\n",
      " to show NaN values in dfS of CityTemper_data...\n",
      "+---+------------------+-----------------------------+----+-------+--------+---------+\n",
      "| dt|AverageTemperature|AverageTemperatureUncertainty|City|Country|Latitude|Longitude|\n",
      "+---+------------------+-----------------------------+----+-------+--------+---------+\n",
      "|  0|            364130|                       364130|   0|      0|       0|        0|\n",
      "+---+------------------+-----------------------------+----+-------+--------+---------+\n",
      "\n",
      "Temperature Df drop all row with blank ['AverageTemperature']... \n",
      "\n",
      "How many NaN values in Temperature dfS ... 364130\n",
      "Droping NaN for Temperature with subset ['AverageTemperature'] ... \n",
      "\n",
      " \n",
      " Row number of  Temperature dfS before drop_duplicates by ['City'] is: 8235082 \n",
      "\n",
      "Drop duplicate with subset 'dt' ... \n",
      " {}\n",
      " \n",
      " Row number of Temperature dfS after drop_duplicates  by ['City'] is: 3448  \n",
      "\n",
      "\n",
      " Loading data to table .... \n",
      "\n",
      "Show schema of new output_temperature_dfS  ...\n",
      "\n",
      "root\n",
      " |-- AirPortCode: string (nullable = true)\n",
      " |-- DateTime: timestamp (nullable = true)\n",
      " |-- AvgTemperature: double (nullable = true)\n",
      " |-- CityName: string (nullable = true)\n",
      " |-- Latitude: string (nullable = true)\n",
      " |-- Longitude: string (nullable = true)\n",
      "\n",
      "+-----------+-------------------+------------------+---------+--------+---------+\n",
      "|AirPortCode|           DateTime|    AvgTemperature| CityName|Latitude|Longitude|\n",
      "+-----------+-------------------+------------------+---------+--------+---------+\n",
      "|       null|1743-11-01 00:00:00|              7.52|  Antwerp|  50.63N|    3.80E|\n",
      "|       null|1832-01-01 00:00:00|             25.32| Araruama|  23.31S|   42.82W|\n",
      "|       null|1796-01-01 00:00:00|22.671999999999997|Bangalore|  12.05N|   77.26E|\n",
      "|       null|1829-05-01 00:00:00|            14.478|    Benxi|  40.99N|  123.55E|\n",
      "|       null|1881-03-01 00:00:00|17.115000000000002|Cajamarca|   7.23S|   78.65W|\n",
      "+-----------+-------------------+------------------+---------+--------+---------+\n",
      "only showing top 5 rows\n",
      "\n",
      "\n",
      " how many rows in new table ... 3448\n",
      "\n",
      " Writing and Reading Parquet files for dfS WorldTemp ... \n",
      "\n",
      "Do Quality check: data existing and data consistency... \n",
      "\n",
      "Data is Existing in target tables and is Consistent before and after Write parquet. OK NOW, MOVE NEXT! \n",
      "FINISHED PROCESS ALL DATA SET INCLUDE DATA QUALITY CHECK \n",
      "\n",
      "show out evidence of WorldTemp dataset with > 1mils rows .. \n",
      "\n",
      "Please note, Final Temp table is droped NaN and duplicated by `City` above ...\n",
      "\n",
      "Total of row in WorldTemp data set is 364130 + 8235082 + 3448\n",
      "show out evidence of Immigration dataset is large > 1mils row ... \n",
      "\n",
      "This is number of row of Fact_Immigration table by staging only one sas7bdat file 3096313\n",
      " \n",
      "\n",
      "Do SQL command to: group count immigrants by their cities and include the foreign_born field in this city. The results could be ordered by the immigrant counts to see if cities with the most immigrants are indeed cities with the largest foreign-born counts \n",
      " \n",
      " \n",
      "+------------+\n",
      "|count_F_Immg|\n",
      "+------------+\n",
      "|      485762|\n",
      "|      343193|\n",
      "|      310001|\n",
      "|      152462|\n",
      "|      149164|\n",
      "|      130464|\n",
      "|      101433|\n",
      "|       95898|\n",
      "|       92528|\n",
      "|       89148|\n",
      "|       71781|\n",
      "|       57275|\n",
      "|       47687|\n",
      "|       38847|\n",
      "|       37669|\n",
      "|       25607|\n",
      "|       24957|\n",
      "|       18230|\n",
      "|       17502|\n",
      "|       16220|\n",
      "|       12666|\n",
      "|        9804|\n",
      "|        9063|\n",
      "|        8928|\n",
      "|        7066|\n",
      "|        5114|\n",
      "|        5100|\n",
      "|        4490|\n",
      "|        4271|\n",
      "|        3501|\n",
      "|        3469|\n",
      "|        2970|\n",
      "|        2175|\n",
      "|        1719|\n",
      "|        1605|\n",
      "|        1000|\n",
      "|         943|\n",
      "|         777|\n",
      "|         621|\n",
      "|         586|\n",
      "|         562|\n",
      "|         542|\n",
      "|         512|\n",
      "|         419|\n",
      "|         392|\n",
      "|         354|\n",
      "|         337|\n",
      "|         329|\n",
      "|         244|\n",
      "|         238|\n",
      "+------------+\n",
      "only showing top 50 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%run etl.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
